# %%

# PredictThyroid – Model Comparison Notebook

# %% [markdown]
# <img src="images/Thyroid.png" alt="Image About Thyroid" width="200" height="300">

# %% [markdown]
# ## Thyroid dataset:
# 
# .datasets/thyroid.csv

# %% [markdown]
# # Questions:

# %% [markdown]
# 4.	Create a Jupyter notebook that includes the following: 
#     * a. All the EDA operation to understand the data including descriptive statistics and at least 8–10 visualizations. 
#     * b. Each analysis must have explanation regarding what inference you get from the data.
# 5.	Each block of code on your Jupyter notebook must have explanations.
# 6.	Answer the following questions in your notebook:
#     * a. What is the Pearson correlation coefficient? 
#     * b. How is each attribute important for predicting the target (heat map)?
#     * c. What is k-fold cross-validation?
#     * d. Why is the training dataset 70–80%? Why is the test dataset 20–30%?

# %% [markdown]
# - Preprocessing with ColumnTransformer (numeric/categorical)
# - Stratified split
# - 3 models: Logistic Regression, Random Forest and XGBoost (fallback to Gradient Boosting)
# - Metrics (Accuracy, Precision, Recall, F1, ROC-AUC), confusion matrices, ROC curves
# - Generates `predictThyroid_model_report.csv`

# %%
%matplotlib inline
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, roc_curve, auc, confusion_matrix, classification_report
)
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.utils.multiclass import type_of_target

try:
    from xgboost import XGBClassifier
    XGB_AVAILABLE = True
except Exception:
    XGB_AVAILABLE = False
    print("XGBoost not available, using GradientBoostingClassifier as fallback.")

# %%

# Target config and CSV detection
TARGET_NAME = None  # set manually if auto-detection fails

candidate_paths = [
    './datasets/thyroid.csv'
  ]

csv_path = None
for p in candidate_paths:
    if os.path.exists(p):
        csv_path = p
        break

if csv_path is None:
    raise FileNotFoundError("Place the CSV as 'predictThyroid.csv'/'thyroid.csv' in the notebook directory or in /mnt/data/.")

print(f"Using dataset at: {csv_path}")
df = pd.read_csv(csv_path)
print("Shape:", df.shape)
display(df.head())

if TARGET_NAME is None:
    common_targets = ['Outcome','outcome','target','Target','class','Class','label','Label','diagnosis','Diagnosis','y','Y']
    found = [c for c in df.columns if c in common_targets]
    if len(found) >= 1:
        TARGET_NAME = found[0]
        print("Auto-detected target:", TARGET_NAME)
    else:
        # Heuristic fallback: prefer small-cardinality columns (2..10 unique)
        candidates = []
        for c in df.columns:
            try:
                nuniq = df[c].nunique(dropna=True)
            except Exception:
                continue
            if 2 <= nuniq <= 10:
                candidates.append((c, nuniq))
        if candidates:
            candidates.sort(key=lambda x: x[1])
            TARGET_NAME = candidates[0][0]
            print("Heuristic target (small cardinality):", TARGET_NAME)
        else:
            TARGET_NAME = df.columns[-1]
            print("Fallback target (last column):", TARGET_NAME)

# %% [markdown]
# ## Heatmap de Correlação (Pearson)
# 

# %%

# === Imports para o Heatmap (seguros se já existentes) ===
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Correlation heatmap for numeric and encoded features
TARGET = "Recurred"

# 1. Prepare numeric features
numeric_features = ['Age']  # Add other numeric features if needed
df_numeric = df[numeric_features]

# 2. Prepare categorical features
cat_features = [col for col in df.columns if col not in numeric_features + [TARGET]]
ohe = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')
X_cat_ohe = ohe.fit_transform(df[cat_features])
ohe_feature_names = ohe.get_feature_names_out(cat_features)
df_ohe = pd.DataFrame(X_cat_ohe, columns=ohe_feature_names, index=df.index)

# 3. Add target encoding
df_ohe['Target'] = (df[TARGET] == 'Yes').astype(int)

# 4. Combine numeric and encoded features
combined_data = pd.concat([df_numeric, df_ohe], axis=1)

# 5. Calculate correlation matrix
combined_corr = combined_data.corr().round(3)

# 6. Plot correlation heatmap
plt.figure(figsize=(12, 10))
mask = np.triu(np.ones_like(combined_corr), k=1)  # mask upper triangle
sns.heatmap(combined_corr, 
            mask=mask,
            annot=True,
            cmap='coolwarm',
            center=0,
            fmt='.2f',
            square=True,
            linewidths=.5,
            cbar_kws={"shrink": .5})
plt.title('Feature Correlation Matrix\n(Numeric + One-hot Encoded Features)')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# 7. Show top correlations with target
target_correlations = combined_corr['Target'].drop('Target').abs().sort_values(ascending=False)
print("\nTop absolute correlations with target:")
print(target_correlations.head(10))

# 8. Violin plots for top correlated features
plt.figure(figsize=(15, 5))
top_features = target_correlations.head(4).index
for i, feature in enumerate(top_features, 1):
    plt.subplot(1, 4, i)
    if feature in numeric_features:
        sns.violinplot(data=df, x=TARGET, y=feature)
    else:
        # For encoded features, plot the original categorical feature
        orig_feature = feature.split('_')[0]
        if orig_feature in df.columns:
            sns.countplot(data=df, x=orig_feature, hue=TARGET)
            plt.xticks(rotation=45)
    plt.title(f'{feature}')
plt.tight_layout()
plt.show()

# %%

y = df[TARGET_NAME]
X = df.drop(columns=[TARGET_NAME])

num_cols = X.select_dtypes(include=[np.number]).columns.tolist()
cat_cols = [c for c in X.columns if c not in num_cols]

print("Numeric:", num_cols[:12])
print("Categorical:", cat_cols[:12])

ttype = type_of_target(y)
strat = y if ttype in ("binary","multiclass") else None

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=strat
)
X_train.shape, X_test.shape, ttype

# %%

# --- Distribution plot for 'recurred' (or detected target) ---
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# Try preferred column name(s) first; otherwise fall back to TARGET_NAME
preferred_names = ["recurred", "Recurrence", "recurrence", "recur", "Recurred"]
target_col = None

# If a dataframe 'df' exists, figure out which column to plot
try:
    if isinstance(df, pd.DataFrame):
        for cand in preferred_names:
            if cand in df.columns:
                target_col = cand
                break
        if target_col is None:
            # fall back to TARGET_NAME if defined and present in df
            try:
                if 'TARGET_NAME' in globals() and TARGET_NAME in df.columns:
                    target_col = TARGET_NAME
            except Exception:
                pass
except NameError:
    pass

if target_col is None:
    raise RuntimeError(
        "Não encontrei a coluna 'recurred'. Certifique-se de que a base foi carregada em 'df' "
        "e que a coluna alvo ('recurred' ou TARGET_NAME) existe."
    )

vc = df[target_col].value_counts(dropna=False).sort_index()
vc_norm = (vc / vc.sum()).round(4)

plt.figure()
vc.plot(kind="bar")
plt.title(f"Distribuição da variável alvo: {target_col}")
plt.xlabel(target_col)
plt.ylabel("Frequência absoluta")
plt.tight_layout()
plt.show()

# Frequência relativa (em outra figura, ainda 1 por plot)
plt.figure()
vc_norm.plot(kind="bar")
plt.title(f"Distribuição relativa da variável alvo: {target_col}")
plt.xlabel(target_col)
plt.ylabel("Frequência relativa")
plt.tight_layout()
plt.show()

print("Frequência absoluta:")
display(vc.to_frame(name="count"))
print("Frequência relativa:")
display(vc_norm.to_frame(name="proportion"))

# %%

numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler(with_mean=True))
])
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
])
preprocess = ColumnTransformer(
    transformers=[('num', numeric_transformer, num_cols),
                  ('cat', categorical_transformer, cat_cols)],
    remainder='drop'
)
preprocess

# %%

models = {}
models['Logistic Regression'] = Pipeline(steps=[
    ('prep', preprocess),
    ('clf', LogisticRegression(random_state=42, max_iter=2000, multi_class='ovr'))
])
models['Random Forest'] = Pipeline(steps=[
    ('prep', preprocess),
    ('clf', RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1))
])
if XGB_AVAILABLE:
    models['XGBoost'] = Pipeline(steps=[
        ('prep', preprocess),
        ('clf', XGBClassifier(random_state=42, n_estimators=500, learning_rate=0.05,
                              max_depth=4, subsample=0.9, colsample_bytree=0.9,
                              reg_lambda=1.0, eval_metric='mlogloss', tree_method='hist',
                              use_label_encoder=False, n_jobs=-1))
    ])
else:
    models['Gradient Boosting (fallback)'] = Pipeline(steps=[
        ('prep', preprocess),
        ('clf', GradientBoostingClassifier(random_state=42))
    ])
list(models.keys())

# %%

def compute_metrics(y_true, y_pred, y_proba=None, average='weighted'):
    acc  = accuracy_score(y_true, y_pred)
    prec = precision_score(y_true, y_pred, average=average, zero_division=0)
    rec  = recall_score(y_true, y_pred, average=average, zero_division=0)
    f1   = f1_score(y_true, y_pred, average=average, zero_division=0)
    auc_val = np.nan
    ttype = type_of_target(y_true)
    if y_proba is not None:
        try:
            if ttype == 'binary':
                if y_proba.ndim == 2 and y_proba.shape[1] > 1:
                    proba_pos = y_proba[:, 1]
                else:
                    proba_pos = y_proba.ravel()
                auc_val = roc_auc_score(y_true, proba_pos)
            elif ttype == 'multiclass':
                auc_val = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted')
        except Exception:
            pass
    return acc, prec, rec, f1, auc_val

# Ranking de modelos (ajuste a ordem conforme sua preferência)
# Por padrão: F1 > Accuracy > ROC-AUC (weighted)
RANK_ORDER = ['f1', 'accuracy', 'roc_auc_weighted']


results = []
for name, pipe in models.items():
    pipe.fit(X_train, y_train)
    y_pred = pipe.predict(X_test)

    y_proba = None
    clf = pipe.named_steps['clf']
    try:
        if hasattr(clf, "predict_proba"):
            y_proba = pipe.predict_proba(X_test)
        elif hasattr(clf, "decision_function"):
            from sklearn.preprocessing import MinMaxScaler
            s = pipe.decision_function(X_test)
            if s.ndim == 1:
                s = s.reshape(-1, 1)
            y_proba = MinMaxScaler().fit_transform(s)
    except Exception:
        y_proba = None

    acc, prec, rec, f1, auc_val = compute_metrics(y_test, y_pred, y_proba, average='weighted')
    results.append({'model': name, 'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1, 'roc_auc_weighted': auc_val})

results_df = pd.DataFrame(results).sort_values(by=RANK_ORDER, ascending=False).reset_index(drop=True)
# Add a column marking the top row (best model)
if len(results_df) > 0:
    best_flags = [''] * len(results_df)
    best_flags[0] = '*'
    results_df.insert(0, 'best', best_flags)
results_df

# %%

for name, pipe in models.items():
    print("="*70)
    print(name)
    y_pred = pipe.predict(X_test)
    print(classification_report(y_test, y_pred, digits=4))

# %%

labels = np.unique(y_test)
for name, pipe in models.items():
    y_pred = pipe.predict(X_test)
    cm = confusion_matrix(y_test, y_pred, labels=labels)
    plt.figure(figsize=(5,4))
    plt.imshow(cm)
    for (i, j), v in np.ndenumerate(cm):
        plt.text(j, i, str(v), ha='center', va='center')
    plt.title(f"Confusion Matrix – {name}")
    plt.xlabel("Predicted"); plt.ylabel("Actual")
    plt.xticks(ticks=range(len(labels)), labels=labels, rotation=45)
    plt.yticks(ticks=range(len(labels)), labels=labels)
    plt.colorbar(); plt.tight_layout(); plt.show()

# %%

from sklearn.preprocessing import label_binarize

ttype = type_of_target(y_test)
if ttype == 'binary':
    plt.figure(figsize=(6,5))
    for name, pipe in models.items():
        try:
            if hasattr(pipe.named_steps['clf'], "predict_proba"):
                y_proba = pipe.predict_proba(X_test)[:, 1]
            elif hasattr(pipe.named_steps['clf'], "decision_function"):
                from sklearn.preprocessing import MinMaxScaler
                s = pipe.decision_function(X_test).reshape(-1,1)
                y_proba = MinMaxScaler().fit_transform(s).ravel()
            else:
                y_proba = None
            if y_proba is None:
                continue
            fpr, tpr, _ = roc_curve(y_test, y_proba)
            plt.plot(fpr, tpr, label=name)
        except Exception:
            continue
    plt.plot([0,1],[0,1],'--'); plt.xlabel("FPR"); plt.ylabel("TPR"); plt.title("ROC (Binary)")
    plt.legend(); plt.tight_layout(); plt.show()
elif ttype == 'multiclass':
    classes = np.unique(y_test)
    for name, pipe in models.items():
        try:
            if hasattr(pipe.named_steps['clf'], "predict_proba"):
                y_proba = pipe.predict_proba(X_test)
            elif hasattr(pipe.named_steps['clf'], "decision_function"):
                from sklearn.preprocessing import MinMaxScaler
                s = pipe.decision_function(X_test)
                if s.ndim == 1: s = s.reshape(-1,1)
                y_proba = MinMaxScaler().fit_transform(s)
            else:
                y_proba = None
            if y_proba is None:
                continue
            y_bin = label_binarize(y_test, classes=classes)
            plt.figure(figsize=(6,5))
            for i, cls in enumerate(classes):
                fpr, tpr, _ = roc_curve(y_bin[:, i], y_proba[:, i])
                plt.plot(fpr, tpr, label=f"Class {cls}")
            plt.plot([0,1],[0,1],'--'); plt.xlabel("FPR"); plt.ylabel("TPR")
            plt.title(f"ROC (OVR) – {name}"); plt.legend(); plt.tight_layout(); plt.show()
        except Exception:
            continue

# %%

out_csv = "outputs/predictThyroid_model_report.csv"
results_df.to_csv(out_csv, index=False)
print(f"Report saved to: {out_csv}")
results_df

